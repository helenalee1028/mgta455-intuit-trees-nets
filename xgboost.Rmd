### Xgboost

#### Data pre-processing

```{r}
## change zip and sex to dummy variable
temp <- dummyVars(~zip_bins +sex ,data = intuit75k_train)
pred <- predict(temp, newdata = intuit75k_train)
intuit75k_xgb_train <- intuit75k_train %>%
  cbind(pred) %>%
  select(-c('sex','zip_bins','zip_bins.1','sex.Female')) %>%
  mutate(zip801 = ifelse(zip801 == 'Yes',1,0),
         zip804 = ifelse(zip804 == 'Yes',1,0)) %>%
  ## change bizflag, version1,owntaxprod,upgraded,res1 to numeric 
  mutate(upgraded = as.numeric(upgraded)-1,
         owntaxprod =as.numeric(upgraded),
         version1 = as.numeric(version1)-1,
         bizflag =as.numeric(bizflag)-1,
         res1 = as.numeric(res1)-1)

# same operation on test set
temp <- dummyVars(~zip_bins +sex ,data = intuit75k_test)
pred <- predict(temp, newdata = intuit75k_test)
intuit75k_xgb_test <- intuit75k_test %>%
  cbind(pred) %>%
  select(-c('sex','zip_bins','zip_bins.1','sex.Female')) %>%
  mutate(zip801 = ifelse(zip801 == 'Yes',1,0),
         zip804 = ifelse(zip804 == 'Yes',1,0)) %>%
  mutate(upgraded = as.numeric(upgraded)-1,
         owntaxprod =as.numeric(upgraded),
         version1 = as.numeric(version1)-1,
         bizflag =as.numeric(bizflag)-1,
         res1 = as.numeric(res1)-1)
```

#### Create xgboost-specific DMatrix

```{r}
X_train = model.matrix(res1~.,intuit75k_xgb_train)
y_train = intuit75k_xgb_train$res1

X_test = model.matrix(res1~.,intuit75k_xgb_test)
y_test = intuit75k_xgb_test$res1

dtest <- xgb.DMatrix(data = X_test, label = y_test)
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
```

#### Tune general parameter in xgboost model--nrounds, eta and max_depth

First, tune general parameters -- nrounds, eta and max_depth because they are hyperparameters and may better be trained at first. As for other parameters, we choose to use default value in this round.

```{r eval = FALSE}
## create vector storing paremeters. 
nrounds = c(20,30)
objective = "binary:logistic"
eta <- c(0.2,0.3)
max_depth <- c(6,7,8)
## create grid search matrix
params <- expand.grid(nrounds,objective,eta,max_depth)
#params$auc <- NA
colnames(params) <- c("nrounds",'objective', "eta",'max_depth')


auc <- c()
train_auc <-c()
for (i in 1:nrow(params)){
 
  xgb <- xgb.train(
    nrounds = params[i,1],
    params = as.list(params[i,-1]),
    data = dtrain,
    watchlist = list(val = dtest, train = dtrain),
    print_every_n = 10,
    eval_metric = "auc")
  auc_ <- tail(xgb$evaluation_log$val_auc,1)
  train_auc_ <- tail(xgb$evaluation_log$train_auc,1)
  auc<- c(auc,auc_)
  train_auc <-c(train_auc,train_auc_)
}
params$auc <- auc
params$train_auc <- train_auc
saveRDS(params, "data/xgb_tune.rds")
```

```{r}
readRDS("data/xgb_tune.rds")
```
From the table with all combinations and auc values, we can tell that the best eta is 0.2. Also, the best nround would be something between 20 and 30. We then use this for further tuning. As max_depth of 6 does better than max_depth of 7 or 8, we conclude that the best max_depth would be something smaller than 6. 

Second,we create a random search and generate random combinations of parameters to find the best-performed models. We can afford to test parameters with wider range in random search compared to grid search. We use random search to narrow down parameter range and then put into gird search to get more accurate values.

```{r eval = FALSE}
nrounds_ = seq(20,30,1)
objective_ = "binary:logistic"
eta_ <- c(0.2)
max_depth_ <- seq(1,6,1)
subsample_ <- seq(0.4,1,0.1)
colsample_bytree_ <- seq(0.4,1,0.1)
gamma_ <- c(0,0.2,0.1)
min_child_weight_ <- seq(1,10,1)

df <- as.data.frame(matrix(NA, ncol = 9, nrow = 100))
colnames(df) <- c('nrounds','objective','eta','max_depth','subsample','colsample_bytree','gamma','min_child_weight','auc')
for (i in 1:100){
  
  nrounds <- sample(nrounds_,1)
  objective <- sample(objective_,1)
  eta <- sample(eta_,1)
  max_depth <- sample(max_depth_,1)
  subsample<- sample(subsample_,1)
  colsample_bytree <- sample(colsample_bytree_,1)
  gamma <- sample(gamma_,1)
  min_child_weight <- sample(min_child_weight_,1)
  
  
  temp <- data.frame('nrounds' = nrounds,'objective' = objective,
"eta" = eta,'max_depth' =max_depth ,'subsample' =subsample, 'colsample_bytree' =colsample_bytree ,'gamma' = gamma,'min_child_weight' = min_child_weight)
  params <- as.list(temp)
  x <-c(nrounds,objective,eta,max_depth,subsample,colsample_bytree,gamma,min_child_weight)
  
  xgb <- xgb.train(
    nrounds =nrounds,
    params = as.list(params[-1]),
    data = dtrain,
    watchlist = list(val = dtest, train = dtrain),
    print_every_n = 5,
    eval_metric = "auc")
  auc_ <- tail(xgb$evaluation_log$val_auc,1)
  x <- c(x,auc_)
  df[i,] <-x

}

df <- arrange(df, desc(df$auc))
saveRDS(df, "data/df.rds")

```

```{r}
df_read <-readRDS("data/df.rds")
df_read[1:10,]
```

From the stored dataframe, we calculate the average parameters of the top 10 rows. We found the best max_depth is 4, best subsample between 0.8 and 1, colsample also between 0.8 and 1. Gamma = 0 is better. 

Then we do grid search for more accurate estimate for nrounds,subsample and min_child_weight.

```{r eval = FALSE}
## First tune best nrounds
nrounds = c(20,30)
objective = "binary:logistic"
eta <- c(0.2)
max_depth <- c(4)
subsample <- seq(0.8,1,0.2)
colsample_bytree <- c(0.8)
gamma <- c(0)
min_child_weight <- seq(4,10,3)
#nrounds = c(20,30,50,100,200,500)
#eta <- c(0.1,0.2,0.3)
#max_depth <- c(4,5,6,7,8)
params <- expand.grid(nrounds,objective,eta,max_depth,subsample,colsample_bytree,gamma,min_child_weight)
#params$auc <- NA
colnames(params) <- c("nrounds",'objective', "eta",'max_depth','subsample','colsample_bytree','gamma','min_child_weight')


auc <- c()
train_auc <-c()
for (i in 1:nrow(params)){
 
  xgb <- xgb.train(
    nrounds = params[i,1],
    params = as.list(params[i,-1]),
    data = dtrain,
    watchlist = list(val = dtest, train = dtrain),
    print_every_n = 10,
    eval_metric = "auc")
  auc_ <- tail(xgb$evaluation_log$val_auc,1)
  train_auc_ <- tail(xgb$evaluation_log$train_auc,1)
  auc<- c(auc,auc_)
  train_auc <-c(train_auc,train_auc_)
}
params$auc <- auc
params$train_auc <- train_auc
saveRDS(params, "data/xgb_tune_all.rds")
#xgb_tune <- xgb_tune[,-4]
```

```{r}
tune_all <-readRDS("data/xgb_tune_all.rds")
tune_all
```

From the result, the best nrounds is 30, eta = 0.2,max_depth = 4, subsample is 0.8, colsamply_bytree is 0.8, gamma is 0. min_child_weight is 10.

#### Train best xgboost model and make prediction

We trained our best model, make prediction on test set and store the estimated probability is stored in column 'pred_xgb' in dataframe 'intuit75k_test'.

Based on this model, the estimated profit for wave-2 emailing would be around $440,000 dollars.

```{r}
params <- list(
  objective = "binary:logistic",
  eta = 0.2,
  max_depth = 4,
  colsamply_bytree = 0.8,
  min_child_weight = 10,
  subsample = 0.8
  #gamma = 10
)

xgb <- xgb.train(
    nrounds = 30,
    params = params,
    data = dtrain,
    watchlist = list(val = dtest, train = dtrain),
    print_every_n = 10,
    eval_metric = "auc")
AUC <- tail(xgb$evaluation_log$val_auc,1)

pred = predict(xgb, dtest)
intuit75k_test$`pred_xgb` <- pred
model_eval(intuit75k_test, 'pred_xgb')

saveRDS(pred, "data/xgb_best.rds")

```
