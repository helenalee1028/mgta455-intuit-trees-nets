---
  title: "Helena"
author: "Wenrui_Li"
date: "2/18/2019"
output: html_document
---
  
  ```{r r_setup, include = FALSE}
## initial settings
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 144,
  warning = FALSE
)

## width to use when printing tables etc.
options(
  width = 250,
  scipen = 100,
  max.print = 5000,
  stringsAsFactors = FALSE
)

## load radiant packages if needed
if (!exists("r_environment")) library(radiant)
```

<style>
  .table {
    width: auto;
  }
ul, ol {
  padding-left: 18px;
}
pre, code, pre code {
  overflow: auto;
  white-space: pre;
  word-wrap: normal;
  background-color: #ffffff;
}
</style>
```{r}
## loading the data. Note that data must be loaded from the data/
## in the rstudio project directory
intuit75k <- readr::read_rds(file.path(radiant.data::find_dropbox(), "MGTA455-2019/data/intuit75k.rds"))
```

```{r}
library(tidyverse)
library(rpart)
library(ipred)
library(caret)
library(randomForest)
library(gbm)
library(radiant)
```


```{r}
## change variable types for 5 factor variables

intuit75k <- intuit75k %>% 
  mutate(zip801 = ifelse(zip == "00801", "Yes", "No"),
         zip804 = ifelse(zip == "00804", "Yes", "No"))

intuit75k <- mutate_at(intuit75k, .vars = vars(zip_bins, bizflag, version1, owntaxprod, upgraded, zip801, zip804), .funs = funs(as.factor))

class(intuit75k$res1)

train = intuit75k %>%
  filter(training == 1)

test = intuit75k %>%
  filter(training == 0)
```

```{r}
mail_cost <- 1.41
margin_revenue <- 60
breakeven_rate <- mail_cost/margin_revenue

overall_val_resp <- mean(test$res1 == "Yes")

cm <- function(dat, vars){
  
  cm_df <- as.data.frame(matrix(NA, ncol = 3, nrow = length(vars)))
  colnames(cm_df) <- c("var", "auc", "tpr")
  
  for (i in 1:length(vars)){
    
    var <- vars[i]
    probs <- pull(dat, !!var)
    resp <- pull(dat, "res1")
    
    mailto <- ifelse(pull(dat, !!var) > breakeven_rate, "TRUE", "FALSE") # decide whether to mail or not
    
    tpr <- sum(resp =="1" & mailto == "TRUE")/sum(resp == "1")
    auc <- ModelMetrics::auc(resp, probs)
    
    cm_vec <- c(var, auc, tpr)
    cm_df[i,] <- cm_vec
  }
  
  cm_df[,2:3] <- apply(cm_df[,2:3],2,as.numeric)
  return(cm_df)
}

model_eval <- function(dat, vars){
  
  # calculate expected scaled profits and ROME
  
  eval_df <- as.data.frame(matrix(NA, ncol = 6, nrow = length(vars)))
  colnames(eval_df) <- c("var","nr_mail", "rep_rate_w2", "nr_resp_w2", "profit", "ROME")
  
  
  for (i in 1:length(vars)){
    
    var <- vars[i]
    
    mailto <- ifelse(pull(dat, !!var) > 2 * breakeven_rate, "TRUE", "FALSE") # decide whether to mail or not
    mailto_rate <- mean(mailto == "TRUE")
    nr_mail <- mailto_rate * (801821 - 38487) #target size
    
    resp <- pull(dat, "res1") # extract respondents
    
    rep_rate_w1 <- sum(resp == "Yes" & mailto == "TRUE")/sum(mailto=="TRUE") # response rate among targeted audience
    rep_rate_w2 <- rep_rate_w1 * 0.5
    nr_resp_w2 <- rep_rate_w2 * nr_mail # response customers among targeted audience
    
    sum_cost <- mail_cost * nr_mail
    revenue <- margin_revenue * nr_resp_w2
    profit <- revenue - sum_cost
    ROME <- profit/sum_cost
    
    perf_vec <- c(var, nr_mail, rep_rate_w2, nr_resp_w2, profit, ROME)
    
    eval_df[i,] <- perf_vec
  }
  
  return(eval_df) 
}

lift_gain_plot <- function(dat, vars){
  
  lift_gain_df <- as.data.frame(matrix(NA, ncol = 4))
  colnames(lift_gain_df) <- c("resp_decile", "cumulative_gain", "cumulative_lift", "var")
  
  for (i in 1:length(vars)){
    
    var <- vars[i]
    
    probs <- pull(dat, !!var)
    resp <- pull(dat, "res1")
    
    lg_dat <- data.frame(probs, resp)
    lg_dat <- lg_dat %>% 
      mutate(resp_decile = xtile(probs, n = 10, rev = T)) %>% 
      group_by(resp_decile) %>% 
      summarise(n_customer = n(),
                n_buyer = sum(resp == "1")) %>%
      mutate(cum_customer = cumsum(n_customer),
             cum_buyer = cumsum(n_buyer),
             cumulative_lift = (cum_buyer/cum_customer)/overall_val_resp,
             cumulative_gain = cum_buyer/sum(n_buyer)) %>% 
      select(resp_decile, cumulative_gain, cumulative_lift)
    
    lg_dat[,var] <- var
    
    lift_gain_df <- rbind(lift_gain_df, setNames(lg_dat, names(lift_gain_df)))
  }
  
  lift_gain_df <- lift_gain_df[-1,] #remove first null row
  lift_gain_df$prop_customer <- rep(seq(0.1,1, 0.1),length(vars))
  
  # plot cumulative lift
  p1 <- lift_gain_df %>% 
    ggplot(aes(x = prop_customer, y = cumulative_lift, group = var)) + 
    geom_point(aes(color = var)) + geom_line(aes(color = var))+
    geom_hline(yintercept = 1, color = "black")
  
  
  
  # plot cumulative gain
  p2 <- lift_gain_df %>% 
    ggplot(aes(x = prop_customer, y = cumulative_gain, group = var)) + 
    geom_point(aes(color = var)) + geom_line(aes(color = var))+
    geom_line(aes(y = prop_customer), color = "black")
  
  gridExtra::grid.arrange(p1,p2, nrow = 2)
  
}

```


## Decision Tree (loosen the control)
```{r}
decision_tree = rpart(formula = res1 ~ zip_bins + numords + dollars + last + version1 + owntaxprod + upgraded + zip801 + zip804, data = train, control=rpart.control(minsplit=2, minbucket=1, cp=0.001))
```

```{r}
test$decision_tree_pred = predict(decision_tree, newdata = test, type = 'prob')
```

## Bagging
```{r}
bagging = bagging(formula = res1 ~  zip_bins + numords + dollars + last + version1 + owntaxprod + upgraded + zip801 + zip804, data = train, nbagg=50)
test$bagging_pred = predict(object = bagging, newdata = test, type = 'prob')
```

## treebag cross-validation
```{r}
ctrl = trainControl(method = 'cv', number = 5)
treebag = train(res1 ~ zip_bins + numords + dollars + last + version1 + owntaxprod + upgraded + zip801 + zip804, data = train, method = 'treebag', trControl = ctrl)
test$treebag_pred = predict(object = treebag, newdata = test, type = 'prob')$`Yes`
```

## Random Forest
```{r}
random_forest = randomForest(formula = res1 ~  zip_bins + numords + dollars + last + version1 + owntaxprod + upgraded + zip801 + zip804, data = train)
test$random_forest_pred = predict(object = random_forest, newdata = test, type = 'prob')
```

## tuning random forest
```{r}
columns = c("zip_bins","numords","dollars","last","version1","owntaxprod","upgraded","zip801","zip804")
tuning_random_forest <- tuneRF(x = subset(train, select = columns),
                               y = train$res1,
                               ntreeTry = 500, doBest = TRUE)

test$tuning_random_forest_pred = predict(object = tuning_random_forest, newdata = test, type = 'prob')
```

## gbm
```{r}
train$res1 <- ifelse(train$res1 == "Yes", 1, 0)
test$res1 <- ifelse(test$res1 == "Yes", 1, 0)
gbm = gbm(formula = res1 ~  zip_bins + numords + dollars + last + version1 + owntaxprod + upgraded + zip801 + zip804, distribution = 'bernoulli', data = train, n.trees = 100)
test$gbm_pred = predict.gbm(object = gbm, newdata = test, type = 'response',n.trees = 100)
test$res1 <- ifelse(test$res1 == 1, 'Yes', 'No')
```

```{r}
mail_cost <- 1.41
margin_revenue <- 60
breakeven_rate <- mail_cost/margin_revenue
vars_vec = c('decision_tree_pred','bagging_pred','treebag_pred','random_forest_pred','tuning_random_forest_pred','gbm_pred')
model_eval(test,vars_vec)
```
The model with outstanding profits is gbm, so we will focus on tuning the hyparameters of this model.

```{r}
# hyper parameter tuning
interaction.depth <- c(2,4,6)
shrinkage <- c(0.001, 0.01, 0.1)
cv.folds <- c(2,4,6)

# build parameters matrix and keep auc performance
params <- expand.grid(interaction.depth, shrinkage, cv.folds)
params$auc <- NA
colnames(params) <- c("interaction.depth", "shrinkage", "cv.folds", "auc")

train$res1 <- ifelse(train$res1 == "Yes", 1, 0)
test$res1 <- ifelse(test$res1 == "Yes", 1, 0)

train = train[,-c(1,2)]
test = test[,-c(1,2)]

# train gbm models and keep track of test data performance
for (i in 1:nrow(params)){
  set.seed(123)
  gbm_tune <- gbm(formula = res1 ~ . , 
                  data = train, 
                  distribution = "bernoulli", 
                  interaction.depth = params[i,1],
                  shrinkage = params[i,2],
                  cv.folds = params[i,3],
                  n.trees = 100)
  print(i)
  pred_tune <- predict(gbm_tune, newdata = test, type = "response", n.trees = 100)
  auc <- auc(pred_tune, test$res1)
  params[i,4] <- auc

}

saveRDS(params, "gbm_tune.rds")


params %>% 
  top_n(auc, n = 5) 

```


```{r}
# based on our previous tuning results, we'll split our parameters into smaller units and train our models

# hyper parameter tuning
interaction.depth <- c(3,4,5)
shrinkage <- c(0.07,0.08,0.09,0.1)
cv.folds <- c(6)

# build parameters matrix and keep auc performance
params2 <- expand.grid(interaction.depth, shrinkage, cv.folds)
params2$auc <- NA
colnames(params2) <- c("interaction.depth", "shrinkage", "cv.folds", "auc")

# train gbm models and keep track of test data performance
for (i in 1:nrow(params2)){
  set.seed(123)
  gbm_tune2 <- gbm(formula = res1 ~ . , 
                   data = train, 
                   distribution = "bernoulli", 
                   interaction.depth = params2[i,1],
                   shrinkage = params2[i,2],
                   cv.folds = params2[i,3],
                   n.trees = 100)
  print(i)
  pred_tune2 <- predict(gbm_tune2, newdata = test, type = "response", n.trees = 100)
  auc2 <- ModelMetrics::auc(test$res1,pred_tune2)
  params2[i,4] <- auc2
  
}

saveRDS(params2, "gbm_tune2.rds")

params2 %>% 
  arrange(desc(auc)) %>% 
  top_n(auc, n = 8)
```

After 2nd round of hyperparameters tuning, we decide to use 8 top performing gbm models in terms of auc and calculate expected profits, since higher AUC doesn't mean higher profit.

```{r}
params2 <- readRDS("gbm_tune2.rds")
optimal_params_gbm <- params2 %>% 
arrange(desc(auc)) %>% 
top_n(auc, n = 8) %>% 
select(-auc)

gbm_preds <- matrix(NA, ncol = nrow(optimal_params_gbm), nrow = nrow(test))

for (i in 1:nrow(optimal_params_gbm)){
set.seed(123)
gbm_tune <- gbm(formula = res1 ~ . , 
data = train, 
distribution = "bernoulli", 
interaction.depth = optimal_params_gbm[i,1],
shrinkage = optimal_params_gbm[i,2],
n.trees = 100)
print(i)
pred_tune <- predict(gbm_tune, newdata = test, type = "response", n.trees = 100)
gbm_preds[,i] <- pred_tune
}


# cbind the predictions to intuit75_test dataframe and put into evaluations
colnames(gbm_preds) <- paste(rep("gbm", 8), c(1:8))
test <- cbind(test, gbm_preds)

vars <- tail(colnames(test), 8)
test$res1 <- ifelse(test$res1 == 1, 'Yes', 'No')
model_eval(test, vars)
cm(intuit75k_test, vars)
lift_gain_plot(intuit75k_test, vars)
```

Tune n.trees parameter value to 200
```{r}
optimal_params_gbm2 <- params2 %>% 
arrange(desc(auc)) %>% 
top_n(auc, n = 8) %>% 
select(-auc)

gbm_preds2 <- matrix(NA, ncol = nrow(optimal_params_gbm2), nrow = nrow(test))

for (i in 1:nrow(optimal_params_gbm2)){
set.seed(123)
gbm_tune <- gbm(formula = res1 ~ . , 
data = train, 
distribution = "bernoulli", 
interaction.depth = optimal_params_gbm2[i,1],
shrinkage = optimal_params_gbm2[i,2],
n.trees = 200)
print(i)
pred_tune <- predict(gbm_tune, newdata = test, type = "response", n.trees = 200)
gbm_preds2[,i] <- pred_tune
}


# cbind the predictions to intuit75_test dataframe and put into evaluations
colnames(gbm_preds2) <- paste(rep("gbm2", 8), c(1:8))
test$res1 <- ifelse(test$res1 == 1, 'Yes', 'No')
test2 <- cbind(test, gbm_preds2)
vars2 <- tail(colnames(test2), 8)

model_eval(test2, vars2)
cm(test2, vars2)
lift_gain_plot(test2, vars2)
```

So the best model we select in the end has the highest profit of 459466.00128 on the test set. It has the hyperparameters of 3 interaction depth, shrinkage of 0.1. 
